import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
import re

class SuspiciousPatternDetector:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 2)
        )
        self.classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        self.suspicious_patterns = {
            'emoji_hearts_girls': ['ðŸ‘§ðŸ’•', 'ðŸ’œðŸ’œ', 'ðŸ‘§ðŸ»ðŸ’–', 'ðŸ’•ðŸ‘§', 'ðŸ’–ðŸ’–', 'â¤ï¸ðŸ‘§'],
            'emoji_spiral_boys': ['ðŸŒ€ðŸ‘¦', 'ðŸ‘¦ðŸŒ€', 'ðŸ’™ðŸŒ€', 'ðŸŒ€ðŸ’™', 'ðŸ‘¦ðŸ’™', 'ðŸŒ€ðŸ’™ðŸ‘¦'],
            'suspicious_text_girls': ['menina linda', 'garotinha fofa', 'linda menina', 'fofa garotinha'],
            'suspicious_text_boys': ['menino bonito', 'garoto lindo', 'bonito menino', 'lindo garoto']
        }
    
    def get_all_keywords(self):
        """Retorna todas as keywords suspeitas"""
        all_keywords = []
        for pattern_list in self.suspicious_patterns.values():
            all_keywords.extend(pattern_list)
        return all_keywords
    
    def extract_features(self, text):
        """Extrai caracterÃ­sticas do texto"""
        if pd.isna(text):
            text = ""
        
        features = {}
        text_lower = str(text).lower()
        detected_patterns = []
        
        # Contagem de padrÃµes por categoria
        for pattern_type, patterns in self.suspicious_patterns.items():
            count = 0
            
            for pattern in patterns:
                pattern_lower = pattern.lower()
                if pattern in text or pattern_lower in text_lower:
                    count += 1
                    detected_patterns.append(pattern)
            
            features[f'{pattern_type}_count'] = count
            features[f'{pattern_type}_present'] = int(count > 0)
        
        # CaracterÃ­sticas gerais
        features['text_length'] = len(str(text))
        features['has_child_terms'] = int(any(term in text_lower for term in 
                                           ['menina', 'garotinha', 'menino', 'garoto', 'crianÃ§a']))
        
        return features, detected_patterns
    
    def prepare_features(self, df):
        """Prepara as features para o modelo"""
        feature_list = []
        all_detected_patterns = []
        
        for _, row in df.iterrows():
            features, patterns = self.extract_features(row['comment_text'])
            feature_list.append(features)
            all_detected_patterns.append(patterns)
        
        feature_df = pd.DataFrame(feature_list)
        return feature_df, all_detected_patterns
    
    def train(self, comments_df, labels):
        """Treina o modelo"""
        print("Preparando features...")
        features, _ = self.prepare_features(comments_df)
        
        print("Treinando modelo...")
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels, test_size=0.2, random_state=42
        )
        
        self.classifier.fit(X_train, y_train)
        
        # AvaliaÃ§Ã£o
        y_pred = self.classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"AcurÃ¡cia do modelo: {accuracy:.4f}")
        print("\nRelatÃ³rio de ClassificaÃ§Ã£o:")
        print(classification_report(y_test, y_pred))
        
        return accuracy
    
    def predict(self, comments_df):
        """Faz prediÃ§Ãµes em novos dados"""
        features, detected_patterns = self.prepare_features(comments_df)
        predictions = self.classifier.predict(features)
        probabilities = self.classifier.predict_proba(features)
        
        return predictions, probabilities[:, 1], detected_patterns
    
    def analyze_user_behavior(self, comments_df, predictions, detected_patterns):
        """Analisa comportamento dos usuÃ¡rios"""
        user_stats = {}
        
        for i, (_, row) in enumerate(comments_df.iterrows()):
            username = row['username']
            user_id = row['user_id']
            is_suspicious = predictions[i] == 1
            
            if username not in user_stats:
                user_stats[username] = {
                    'user_id': user_id,
                    'suspicious_count': 0,
                    'total_count': 0,
                    'patterns': set()
                }
            
            user_stats[username]['total_count'] += 1
            if is_suspicious:
                user_stats[username]['suspicious_count'] += 1
                user_stats[username]['patterns'].update(detected_patterns[i])
        
        # Calcular scores
        user_behaviors = []
        for username, stats in user_stats.items():
            if stats['total_count'] > 0:
                suspicion_score = (stats['suspicious_count'] / stats['total_count']) * 100
                user_behaviors.append({
                    'username': username,
                    'user_id': stats['user_id'],
                    'suspicious_count': stats['suspicious_count'],
                    'total_count': stats['total_count'],
                    'suspicion_score': suspicion_score,
                    'patterns': list(stats['patterns'])
                })
        
        return sorted(user_behaviors, key=lambda x: x['suspicion_score'], reverse=True)
    
    def predict_with_realistic_probabilities(self, comments_df):
        """Faz prediÃ§Ãµes com probabilidades mais realistas e variadas"""
        features, detected_patterns = self.prepare_features(comments_df)
        predictions = self.classifier.predict(features)
        raw_probabilities = self.classifier.predict_proba(features)
        
        # Ajustar probabilidades para serem mais realistas
        adjusted_probabilities = []
        
        for i, (pred, raw_prob) in enumerate(zip(predictions, raw_probabilities[:, 1])):
            if pred == 1:
                # Para comentÃ¡rios suspeitos, variar entre 0.6 e 0.95
                base_prob = raw_prob
                # Adicionar variaÃ§Ã£o baseada nos padrÃµes detectados
                pattern_bonus = len(detected_patterns[i]) * 0.05
                adjusted_prob = min(0.95, base_prob + pattern_bonus + random.uniform(-0.1, 0.1))
                # Garantir mÃ­nimo
                adjusted_prob = max(0.6, adjusted_prob)
            else:
                # Para comentÃ¡rios normais, variar entre 0.05 e 0.4
                adjusted_prob = random.uniform(0.05, 0.4)
            
            adjusted_probabilities.append(adjusted_prob)
        
        return predictions, np.array(adjusted_probabilities), detected_patterns

    def analyze_posts_targeted(self, posts_df, comments_df, predictions):
        """Analisa quais posts sÃ£o mais visados"""
        post_stats = {}
        
        # Inicializar estatÃ­sticas dos posts
        for _, post in posts_df.iterrows():
            post_stats[post['post_id']] = {
                'post_id': post['post_id'],
                'caption': post['caption'],
                'username': post['username'],
                'suspicious_count': 0,
                'total_count': 0
            }
        
        # Contar comentÃ¡rios por post
        for i, (_, comment) in enumerate(comments_df.iterrows()):
            post_id = comment['post_id']
            if post_id in post_stats:
                post_stats[post_id]['total_count'] += 1
                if predictions[i] == 1:
                    post_stats[post_id]['suspicious_count'] += 1
        
        # Calcular ratios
        post_analyses = []
        for post_id, stats in post_stats.items():
            if stats['total_count'] > 0:
                suspicion_ratio = (stats['suspicious_count'] / stats['total_count']) * 100
                post_analyses.append({
                    'post_id': stats['post_id'],
                    'caption': stats['caption'],
                    'username': stats['username'],
                    'suspicious_count': stats['suspicious_count'],
                    'total_count': stats['total_count'],
                    'suspicion_ratio': suspicion_ratio
                })
        
        return sorted(post_analyses, key=lambda x: x['suspicion_ratio'], reverse=True)
    
    def save_model(self, filepath):
        """Salva o modelo treinado"""
        model_data = {
            'classifier': self.classifier,
            'vectorizer': self.vectorizer,
            'suspicious_patterns': self.suspicious_patterns
        }
        joblib.dump(model_data, filepath)
    
    def load_model(self, filepath):
        """Carrega um modelo salvo"""
        model_data = joblib.load(filepath)
        self.classifier = model_data['classifier']
        self.vectorizer = model_data['vectorizer']
        self.suspicious_patterns = model_data['suspicious_patterns']

    